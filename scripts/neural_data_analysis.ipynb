{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4wx/vwT2kBmkSoyJRjGCk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"de8f14ec"},"source":["# Programming for Neuroscience\n","\n","This notebook explores basic concepts related to analyzing audio stimuli and neural responses, relevant to understanding how the brain processes sound.\n","\n","**Outline:**\n","- Exploring audio stimuli for four categories (cat, dog, cow, and rooster).\n","- Analyzing neural data and visualizing responses to stimuli.\n","- Comparing neural responses across different stimulus categories.\n","\n","\n","## Research question: Which animal does the ferret like the most?\n","(Or more scientific: which sound drives the strongest response in the ferret auditory cortex?)\n"]},{"cell_type":"markdown","source":["Let's start by first mounting the drive."],"metadata":{"id":"sU-2eHJaaSXT"}},{"cell_type":"code","execution_count":28,"metadata":{"id":"nlyaXXVU2wlu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758164236907,"user_tz":420,"elapsed":17,"user":{"displayName":"Satyabrata Parida","userId":"16752910670274621070"}},"outputId":"9888a95a-d772-497c-a2e9-3946029fbc8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive.\n","/content/drive/MyDrive/OHSU_files/Teaching/bootcamp_colab\n","Current directory has the following folders: ['scripts', 'figures', 'stimuli', 'processed_data']\n"]}],"source":["import os\n","from google.colab import drive\n","\n","# Check if drive is already mounted to avoid remounting\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Drive already mounted at /content/drive.\")\n","\n","%cd /content/drive/MyDrive/OHSU_files/Teaching/bootcamp_colab/\n","print(f\"Current directory has the following folders: {os.listdir()}\")"]},{"cell_type":"markdown","source":["# Exploring stimuli.\n"],"metadata":{"id":"KJrFqJynY9A5"}},{"cell_type":"markdown","source":["## Read all the stimuli in the stimulus folder."],"metadata":{"id":"ljz6zZTMv0e8"}},{"cell_type":"code","metadata":{"id":"b7dbe3af"},"source":["import scipy.io.wavfile\n","\n","# Define the directory path using a relative path from the current working directory\n","# The current working directory is set in the previous cell to /content/drive/MyDrive/OHSU_files/Teaching/bootcamp_colab/scripts/\n","stimuli_dir = './stimuli'\n","\n","# List all files in the directory\n","all_files = os.listdir(stimuli_dir)\n","\n","# Filter for .wav files\n","wav_files = [f for f in all_files if f.endswith('.wav')]\n","\n","print(f\"Found {len(wav_files)} .wav files.\")\n","filenames_to_print = 5\n","print(f\"Printing the names of the first {filenames_to_print} files\")\n","print(wav_files[:filenames_to_print])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load a file.\n","Print out its length, sampling frequency, and duration."],"metadata":{"id":"pk7KGwgIvwg8"}},{"cell_type":"code","source":["# Load one of the wav files (the first one in the list)\n","if wav_files:\n","    first_wav_file_path = os.path.join(stimuli_dir, wav_files[0])\n","    rate, data = scipy.io.wavfile.read(first_wav_file_path)\n","    print(f\"\\nLoaded the first file: {wav_files[0]}\")\n","    print(f\"Sample rate: {rate}\")\n","    print(f\"Data shape: {data.shape}: duration = {len(data)/rate} seconds\")\n","else:\n","    print(\"\\nNo .wav files found in the directory.\")"],"metadata":{"id":"GlyrKK06vvCS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Plot the file and play sound."],"metadata":{"id":"rJiwpdLZv8U6"}},{"cell_type":"code","metadata":{"id":"6eba4dca"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from IPython.display import Audio\n","\n","# Plot the time waveform\n","plt.figure(figsize=(10, 4))\n","plt.plot(np.linspace(0, len(data) / rate, len(data)), data)\n","plt.xlabel(\"Time (s)\")\n","plt.ylabel(\"Amplitude\")\n","plt.title(f\"Time Waveform: {wav_files[0]}\")\n","plt.grid(True)\n","plt.show()\n","\n","# Play the sound\n","Audio(data, rate=rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"XnYw4LW_--5t"}},{"cell_type":"markdown","metadata":{"id":"8be9be17"},"source":["# Task\n","1.   Analyze the `.wav` filenames to determine the number of unique categories based on the filename prefix (e.g., \"cat_\", \"dog_\").\n","2.   For each unique category, load one file and plot its time waveform."]},{"cell_type":"markdown","metadata":{"id":"1e920ddd"},"source":["## Identify unique categories\n","\n","### Subtask:\n","Extract the category name (e.g., \"cat\", \"dog\") from the beginning of each `.wav` filename."]},{"cell_type":"markdown","source":["## First: We will use a bad implementation (for loop)."],"metadata":{"id":"r52NYIR2VqXK"}},{"cell_type":"code","metadata":{"id":"403df8e9"},"source":["categories_bad_way = []\n","for filename in wav_files:\n","    category = filename.split('_')[0]\n","    categories_bad_way.append(category)\n","\n","print(\"Extracted categories (bad way):\")\n","print(categories_bad_way)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Now, let's use an efficient implementation (using list comprehension)."],"metadata":{"id":"7yS387PDVuG3"}},{"cell_type":"code","source":["categories_good_way = [x.split('_')[0] for x in wav_files]\n","print(\"Extracted categories (good way):\")\n","print(categories_good_way)"],"metadata":{"id":"scMSW2SCV6Fa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Always test your code (when you try something new)"],"metadata":{"id":"rv537Q3ZWIcM"}},{"cell_type":"code","source":["assert categories_bad_way == categories_good_way, \"The two lists are not the same\"\n","# If the two lists are the same, nothing happens and we can move on\n","print(\"Nothing happened: So the two lists are the same\")\n"],"metadata":{"id":"I5x4j1KgWMr9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ea76ce8"},"source":["## Count unique categories\n","\n","### Subtask:\n","Determine the number of unique categories found."]},{"cell_type":"code","metadata":{"id":"7e67e19d"},"source":["unique_categories = set(categories_good_way)\n","num_unique_categories = len(unique_categories)\n","print(f\"\\nNumber of unique categories: {num_unique_categories}\")\n","print(f\"Unique categories: {unique_categories}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"00a5736e"},"source":["## Select one file per category\n","\n","### Subtask:\n","Choose one `.wav` file from each unique category."]},{"cell_type":"code","metadata":{"id":"c702bd8d"},"source":["selected_files = {}\n","for filename in wav_files:\n","    category = filename.split('_')[0]\n","    if category not in selected_files:\n","        selected_files[category] = os.path.join(stimuli_dir, filename)\n","\n","print(\"Selected files for each category:\")\n","for category, filepath in selected_files.items():\n","    print(f\"{category}: {filepath}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dc7218c"},"source":["## Load and plot files\n","\n","### Subtask:\n","Load the selected files and plot the time waveform for each."]},{"cell_type":"code","metadata":{"id":"789d17d9"},"source":["fig, axes = plt.subplots(2, 2, figsize=(8, 5))\n","axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n","\n","for i, (category, filepath) in enumerate(selected_files.items()):\n","    rate, data = scipy.io.wavfile.read(filepath)\n","\n","    time_vector = np.linspace(0, len(data) / rate, len(data))\n","    axes[i].plot(time_vector, data)\n","    axes[i].set_xlabel(\"Time (s)\")\n","    axes[i].set_ylabel(\"Amplitude\")\n","    axes[i].set_title(f\"Time Waveform: {category}\")\n","    axes[i].grid(True)\n","\n","plt.tight_layout() # Adjust layout to prevent overlapping titles/labels\n","plt.show()\n","\n","# Play the sound for each category\n","for category, filepath in selected_files.items():\n","    rate, data = scipy.io.wavfile.read(filepath)\n","    display(Audio(data, rate=rate))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Neural data"],"metadata":{"id":"AmvPI6Qzcq3G"}},{"cell_type":"markdown","source":["## Load neural data and get a sense of the data by printing its keys.\n","Note: Pickle files are handy and powerful, but may not be recommended during Development phase (not ideal for sharing)."],"metadata":{"id":"VNobmMGLXVVo"}},{"cell_type":"code","metadata":{"id":"a573c1fa"},"source":["import pickle\n","import os\n","\n","# Define the file path\n","data_path = './processed_data/recording_rei087.pkl'\n","\n","# Check if the file exists\n","if os.path.exists(data_path):\n","    # Load the data from the pickle file\n","    with open(data_path, 'rb') as f:\n","        saved_neural_data = pickle.load(f) # Load into saved_neural_data as in the previous state\n","\n","    print(f\"Successfully loaded data from: {data_path}\")\n","\n","    print(\"\\nKeys in the loaded data:\")\n","    for key in saved_neural_data.keys():\n","        print(f\"- {key}\")\n","\n","else:\n","    print(f\"File not found: {data_path}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let us look at the meta data to understand how data is saved.\n"],"metadata":{"id":"NfSsDkFNdg88"}},{"cell_type":"code","source":["print(f\"Meta data keys: {saved_neural_data['meta_data'].keys()}\")\n","print(saved_neural_data['meta_data']['data_dims'])"],"metadata":{"id":"4GFmxqzXdbo1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Understanding the data by loading an example\n","Okay - so it means data are saved in the format: ('stimulus_trial', 'neuron_index', 'time_index').\n","\n","*   Let us load data for a single stimulus - let's say a cat sound.\n","*   Then, let's figure out how many trials, neurons, and time samples in the data.\n","* Then plot stimulus, single-trial response, and trial-average response for one example neuron.\n"],"metadata":{"id":"0HRbmkiCd-00"}},{"cell_type":"code","metadata":{"id":"1714a4b5"},"source":["# because data format = ('stimulus_trial', 'neuron_index', 'time_index')\n","trial_ind_in_data = 0\n","neuron_ind_in_data = 1\n","time_ind_in_data = 2\n","\n","# Use 'cat_stim_6.wav' as the demo stimulus\n","demo_stimulus_key = 'cat_stim_6.wav'\n","\n","neural_data = saved_neural_data['neural_data']\n","demo_stim_response = neural_data[demo_stimulus_key]\n","\n","print(f\"Number of stimuli in the dataset: {len(neural_data)}\")\n","print(f\"Shape of the response for the demo stimulus, '{demo_stimulus_key}': {demo_stim_response.shape}\")\n","print(f\"Number of trials: {demo_stim_response.shape[trial_ind_in_data]}\")\n","print(f\"Number of neurons: {demo_stim_response.shape[neuron_ind_in_data]}\")\n","print(f\"Number of time samples: {demo_stim_response.shape[time_ind_in_data]}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's plot for a single demo neuron."],"metadata":{"id":"pnoT6CkXZAG8"}},{"cell_type":"code","source":["demo_neuron_index = 0\n","\n","# --- Plotting ---\n","fig, axes = plt.subplots(3, 1, figsize=(8, 8)) # Reduced figure size\n","axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n","\n","# Plot Stimulus Time Waveform\n","stimulus_filepath = os.path.join(stimuli_dir, demo_stimulus_key)\n","if os.path.exists(stimulus_filepath):\n","    rate, data = scipy.io.wavfile.read(stimulus_filepath)\n","    time_vector_stim = np.linspace(0, len(data) / rate, len(data))\n","    axes[0].plot(time_vector_stim, data)\n","    axes[0].set_xlabel(\"Time (s)\")\n","    axes[0].set_ylabel(\"Amplitude\")\n","    axes[0].set_title(f\"Stimulus Waveform: {demo_stimulus_key}\")\n","    axes[0].grid(True)\n","else:\n","    axes[0].set_title(f\"Stimulus file not found: {demo_stimulus_key}\")\n","\n","\n","# Plot Single-Trial Dot Raster (Demo Neuron: demo_neuron_index)\n","for trial in range(demo_stim_response.shape[0]):\n","  spike_indices = np.where(demo_stim_response[trial, demo_neuron_index, :] > 0)[0]\n","  spike_times = spike_indices / saved_neural_data['meta_data']['fs_Hz']\n","  axes[1].plot(spike_times, np.ones_like(spike_times) * trial, '|', markersize=5, color='k')\n","\n","axes[1].set_xlabel(\"Time (s)\")\n","axes[1].set_ylabel(\"Trial Number\")\n","axes[1].set_title(f\"Single-Trial Raster Plot: {demo_stimulus_key} (Demo Neuron #{demo_neuron_index})\")\n","axes[1].set_yticks(np.arange(demo_stim_response.shape[0]))\n","axes[1].set_ylim(-0.5, demo_stim_response.shape[0] - 0.5)\n","axes[1].grid(True)\n","\n","\n","# Plot Time-Averaged PSTH (Demo Neuron)\n","# Calculate average response across trials\n","avg_response = np.nanmean(demo_stim_response[:, 0, :], axis=0)\n","time_points_psth = np.arange(len(avg_response)) / saved_neural_data['meta_data']['fs_Hz']\n","\n","axes[2].plot(time_points_psth, avg_response)\n","axes[2].set_xlabel(\"Time (s)\")\n","axes[2].set_ylabel(\"Average Response\")\n","axes[2].set_title(f\"Time-Averaged PSTH: {demo_stimulus_key} (Demo Neuron #{demo_neuron_index})\")\n","axes[2].grid(True)\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"2FZxh2c8Y_aD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"u73kRxM8Y_Ly"}},{"cell_type":"markdown","source":["## What about all the neurons (for this stimulus)?"],"metadata":{"id":"kALK3xeii1fW"}},{"cell_type":"code","source":["# --- Plotting ---\n","fig, axes = plt.subplots(2, 1, figsize=(8, 6)) # Reduced figure size\n","axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n","\n","# Plot Stimulus Time Waveform\n","stimulus_filepath = os.path.join(stimuli_dir, demo_stimulus_key)\n","if os.path.exists(stimulus_filepath):\n","    rate, data = scipy.io.wavfile.read(stimulus_filepath)\n","    time_vector_stim = np.linspace(0, len(data) / rate, len(data))\n","    axes[0].plot(time_vector_stim, data)\n","    axes[0].set_xlabel(\"Time (s)\")\n","    axes[0].set_ylabel(\"Amplitude\")\n","    axes[0].set_title(f\"Stimulus Waveform: {demo_stimulus_key}\")\n","    axes[0].grid(True)\n","else:\n","    axes[0].set_title(f\"Stimulus file not found: {demo_stimulus_key}\")\n","\n","# Plot Time-Averaged PSTH (Demo Neuron)\n","# Calculate average response across trials\n","avg_response = np.nanmean(demo_stim_response[:, :, :], axis=(0, 1))  # average along all trials and neurons\n","time_points_psth = np.arange(len(avg_response)) / saved_neural_data['meta_data']['fs_Hz']\n","\n","axes[1].plot(time_points_psth, avg_response)\n","axes[1].set_xlabel(\"Time (s)\")\n","axes[1].set_ylabel(\"Average Response\")\n","axes[1].set_title(f\"Time-Averaged PSTH: {demo_stimulus_key} (All Neurons)\")\n","axes[1].grid(True)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"plXklPvBcXp6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Observations?\n","* Strong response when stimulus starts: Onset response\n","* Strong response when stimulus ends: Offset response"],"metadata":{"id":"AYsYRDrBk6rG"}},{"cell_type":"markdown","source":["# Let's plot the average response for all stimuli in each category."],"metadata":{"id":"3g-lg_1dmCkl"}},{"cell_type":"markdown","metadata":{"id":"533469da"},"source":["## Group stimuli by category\n","\n","### Subtask:\n","Create a dictionary or list that groups the stimulus filenames based on their categories. The dictionary will look like:\n","\n","- **dog**\n","  - dog_stim_1.wav\n","  - dog_stim_2.wav\n","  - ...\n","\n","- **cat**\n","  - cat_stim_1.wav\n","  - cat_stim_2.wav\n","  - ...\n","..."]},{"cell_type":"code","metadata":{"id":"3aefb01c"},"source":["# Create an empty dictionary to store files by category\n","stimuli_by_category = {}\n","\n","# Go through each filename in the list of wav_files\n","for filename in wav_files:\n","    # Extract the category (the part before the first \"_\")\n","    category = filename.split('_')[0]\n","\n","    # If this category is not already in the dictionary, create a new list for it\n","    if category not in stimuli_by_category:\n","        stimuli_by_category[category] = []\n","\n","    # Add the current filename to the list for its category\n","    stimuli_by_category[category].append(filename)\n","\n","# Print the grouped results\n","print(\"Stimuli grouped by category:\")\n","print(stimuli_by_category)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21bca1ad"},"source":["## Calculate average response per category\n","\n","### Subtask:\n","For each category, iterate through all the stimuli in that category, calculate the average neural response across trials and neurons for each stimulus, and then average these stimulus averages to get a category average. Also calculate the standard error of the mean across neurons for each time point within each category.\n"]},{"cell_type":"code","metadata":{"id":"05030c88"},"source":["# Function to calculate average response for a single stimulus across trials and neurons\n","def calculate_stimulus_average(neural_data_stim):\n","    \"\"\"Calculates the average neural response for a single stimulus.\"\"\"\n","    return np.nanmean(neural_data_stim, axis=(0, 1))\n","\n","# Function to calculate average response for a single stimulus across trials for each neuron\n","def calculate_stimulus_neuron_average(neural_data_stim):\n","    \"\"\"Calculates the average neural response across trials for each neuron for a single stimulus.\"\"\"\n","    return np.nanmean(neural_data_stim, axis=0)\n","\n","# Function to calculate SEM across stimuli for each neuron and time point\n","def calculate_stimulus_neuron_sem(stacked_stimulus_neuron_avg):\n","    \"\"\"Calculates the SEM across stimuli for each neuron and time point.\"\"\"\n","    return np.nanstd(stacked_stimulus_neuron_avg, axis=0) / np.sqrt(stacked_stimulus_neuron_avg.shape[0])\n","\n","category_avg_responses = {}\n","category_sem_responses = {}\n","\n","for category, filenames in stimuli_by_category.items():\n","    stimulus_avg_responses = []\n","    stimulus_neuron_avg_responses = [] # List to store neuron-averaged responses per stimulus\n","\n","    for filename in filenames:\n","        neural_data_stim = neural_data[filename]\n","\n","        # Calculate average response across trials and neurons for the stimulus\n","        avg_response_stim = calculate_stimulus_average(neural_data_stim)\n","        stimulus_avg_responses.append(avg_response_stim)\n","\n","        # Calculate average response across trials for each neuron for the stimulus\n","        avg_response_stim_neuron = calculate_stimulus_neuron_average(neural_data_stim)\n","        stimulus_neuron_avg_responses.append(avg_response_stim_neuron)\n","\n","\n","    # Calculate category average by averaging stimulus averages\n","    category_avg_responses[category] = np.nanmean(stimulus_avg_responses, axis=0)\n","\n","    # Stack the stimulus-neuron averages to calculate SEM across stimuli for each time point\n","    # The shape will be (num_stimuli, num_neurons, num_time_points)\n","    stacked_stimulus_neuron_avg = np.stack(stimulus_neuron_avg_responses, axis=0)\n","\n","    # Calculate SEM across stimuli (axis 0) for each neuron and time point using the function\n","    sem_response_stim_neuron = calculate_stimulus_neuron_sem(stacked_stimulus_neuron_avg)\n","\n","    # Calculate the SEM for the category average by averaging the SEM across neurons\n","    category_sem_responses[category] = np.nanmean(sem_response_stim_neuron, axis=0)\n","\n","print(\"Keys in category_avg_responses:\")\n","print(category_avg_responses.keys())\n","print(\"\\nKeys in category_sem_responses:\")\n","print(category_sem_responses.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5d149f1c"},"source":["## Plot average responses with error bars\n","\n","### Subtask:\n","Create a figure with subplots arranged in four columns (one for each category). In each subplot, plot the time-averaged neural response for that category with error bars representing the variability across neurons.\n"]},{"cell_type":"code","metadata":{"id":"2f60d85d"},"source":["# Function to plot average response with error bars for a single category\n","def plot_category_response(ax, category, avg_response, sem_response, time_points):\n","    \"\"\"Plots the average neural response with error bars for a single category.\"\"\"\n","    ax.plot(time_points, avg_response, label=f'{category} Average')\n","    ax.fill_between(time_points, avg_response - sem_response, avg_response + sem_response, alpha=0.3)\n","    ax.set_title(f\"Average Neural Response: {category}\")\n","    ax.set_xlabel(\"Time (s)\")\n","    ax.set_ylabel(\"Average Response\")\n","    ax.grid(True)\n","\n","\n","# Determine the time points based on the sample rate and number of time samples\n","# Get the number of time samples from the shape of one of the neural data arrays\n","# Check if category_avg_responses is not empty before proceeding\n","if category_avg_responses and neural_data:\n","    # Get the first stimulus key to access its neural data shape\n","    first_stim_key = next(iter(neural_data.keys()))\n","    num_time_samples = neural_data[first_stim_key].shape[2] # Assuming time is the 3rd dimension (index 2)\n","    fs_Hz = saved_neural_data['meta_data']['fs_Hz']\n","    time_points = np.arange(num_time_samples) / fs_Hz\n","\n","\n","    # Create a 2x2 grid of subplots for the four categories\n","    fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharex=True, sharey=True)\n","    axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n","\n","    # Iterate through each category and plot its average response with error bars using the function\n","    for i, (category, avg_response) in enumerate(category_avg_responses.items()):\n","        # Get the corresponding standard error of the mean for the current category\n","        sem_response = category_sem_responses[category]\n","\n","        # Call the plotting function for the current category\n","        plot_category_response(axes[i], category, avg_response, sem_response, time_points)\n","\n","    # Adjust layout to prevent overlapping titles/labels\n","    plt.tight_layout()\n","\n","    # Display the plot\n","    plt.show()\n","else:\n","    print(\"No category average responses to plot.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Which category do the neurons like the most?\n","## How will you quantify it?"],"metadata":{"id":"TCoz9FhNnZqj"}}]}